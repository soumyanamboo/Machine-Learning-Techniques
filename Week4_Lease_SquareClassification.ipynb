{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN1X1fEZRc1H0zc2dRhhmai",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soumyanamboo/Machine-Learning-Techniques/blob/main/Week4_Lease_SquareClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lease Square Classification\n",
        "* Lease Square Classification is used for estimating parameters of Discriminant function from the given training data.  \n",
        "* Lease Square Classification adapts linear regression model for classification.  \n",
        "  * It uses lease square error as loss function.  \n",
        "  * It uses normal equation methos and Gradient Descent for estimating model parameters or weight vector.\n",
        "* Since it is a classification algorithm, we would use classification related evaluation metrics such as precision, recall, F-1 Score, AUC ROC/PR and accuracy.\n",
        "* We make use of polynomial feature transformation to obtain new features and then make use of that representation to learn non-linear decision boundaries between classes.   \n",
        "$$ y = w_0 + W^T ùù´(x)   $$  \n",
        "where $ùù´(x)$ is a polynomial feature transformation.\n",
        "* We can tackle the issue of overfitting by using Ridge or Lasso Regularization just like linear regression model."
      ],
      "metadata": {
        "id": "vuDYNoYN0HCJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLzjIMwMzYWW"
      },
      "outputs": [],
      "source": [
        "# Import Libraries:\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "import functools\n",
        "import seaborn as sns\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title [Implementation of Linear Regression class]\n",
        "\n",
        "class LinReg():\n",
        "  ''' Linear Regression Model class definition\n",
        "      y = X@w\n",
        "      X: feature matrix\n",
        "      w: weight vector\n",
        "      y: label vector\n",
        "  '''\n",
        "  def __init__(self):\n",
        "    self.t0 = 20\n",
        "    self.t1 = 100\n",
        "  \n",
        "  def predict(self, X:np.ndarray):\n",
        "    ''' Args:\n",
        "          X: feature matrix\n",
        "        Returns:\n",
        "          y: label vector predicted by the given model\n",
        "    '''\n",
        "    y = X@self.w\n",
        "    return y\n",
        "  \n",
        "  def loss(self, X:np.ndarray, y:np.ndarray, reg_rate:float):\n",
        "    ''' Calculates loss for a model based on known labels.\n",
        "        Args:\n",
        "          X: feature matrix\n",
        "          y: label vector\n",
        "          reg_rate: regularization rate\n",
        "        Returns:\n",
        "          Loss \n",
        "    '''\n",
        "    e = y - self.predict(X)\n",
        "    return (1/2) * np.transpose(e)@e\n",
        "    # return (1/2) * np.transpose(e)@e + (reg_rate/2)*np.transpose(self.w)@self.w\n",
        "  \n",
        "  def rmse(self, X:np.ndarray, y:np.ndarray):\n",
        "    ''' Calculates root mean squared error of prediction w.r.t actual label\n",
        "        Args:\n",
        "          X: feature matrix\n",
        "          y: label vector\n",
        "        Returns:\n",
        "          Loss\n",
        "    '''\n",
        "    return np.sqrt((2/X.shape[0])* self.loss(X,y,0))\n",
        "  \n",
        "  def fit(self, X:np.ndarray, y:np.ndarray, reg_rate:float):\n",
        "    ''' Estimate parameters of linear regression model w.r.t known labels.\n",
        "        Args:\n",
        "          X: feature matrix\n",
        "          y: label vector\n",
        "          reg_rate: rate of regression\n",
        "        Returns:\n",
        "          weight vector\n",
        "    '''\n",
        "    self.w = np.zeros(X.shape[1])\n",
        "    eye = np.eye(np.size(X,1))\n",
        "    self.w = np.linalg.solve(reg_rate*eye + X.T@X, X.T@y)\n",
        "    return self.w\n",
        "  \n",
        "  def calculate_gradient(self, X:np.ndarray, y:np.ndarray, reg_rate:float):\n",
        "    ''' Calculates the gradient of loss function w.r.t weight vector\n",
        "        Args:\n",
        "          X: feature matrix\n",
        "          y: label vector\n",
        "          reg_rate: rate of regression\n",
        "        Returns:\n",
        "          gradient vector\n",
        "    '''\n",
        "    grad = np.transpose(X) @ (self.predict(X) - y) + reg_rate * self.w\n",
        "    return grad\n",
        "  \n",
        "def update_weights(self, grad:np.ndarray, lr:float):\n",
        "  ''' updates the weights based on the gradient of loss function\n",
        "      w_new = w_old - lr * grad\n",
        "      Args:\n",
        "        grad: gradient of loss w.r.t w\n",
        "        lr: learning rate\n",
        "      Returns:\n",
        "      updated weight vector\n",
        "  '''\n",
        "  w_new = self.w - lr * grad\n",
        "  return w_new\n",
        "\n",
        "def learning_schedule(self, t):\n",
        "  return (self.t0/(t + self.t1))\n",
        "\n",
        "def gd(self, X:np.ndarray, y:np.ndarray, num_epochs:int, lr:float,reg_rate:float):\n",
        "  ''' Estimates parameter of linear regression model using gradient descent\n",
        "      Args:\n",
        "        X: feature matrix\n",
        "        y: label vector\n",
        "        num_epochs: number of iterations\n",
        "        lr: learning rate\n",
        "        reg_rate: rate of regression\n",
        "      Returns:\n",
        "        weight vector: final weight vector\n",
        "  '''\n",
        "  self.w = np.zeros(X.shape[1])\n",
        "  self.w_all = []\n",
        "  self.err_all = []\n",
        "  for i in np.arange(0, num_epochs):\n",
        "    \n",
        "    self.w_all.append(self.w)\n",
        "    self.err_all.append(self.loss(X,y,0))\n",
        "    \n",
        "    grad = self.calculate_gradient(X,y,reg_rate)\n",
        "    self.w = self.update_weights(grad,lr)\n",
        "  return self.w\n",
        "\n",
        "def mbgd(self, X:np.ndarray, y:np.ndarray, num_epochs:int, batch_size:int, reg_rate:float):\n",
        "  ''' Estimates parameter of linear regression model using MBGD\n",
        "      Args:\n",
        "        X: feature matrix\n",
        "        y: label vector\n",
        "        num_epochs: number of iterations\n",
        "        batch_size: number of examples in a batch\n",
        "        reg_rate: rate of regression\n",
        "      Returns:\n",
        "        weight vector: final weight vector\n",
        "  '''\n",
        "  self.w = np.zeros(X.shape[1])\n",
        "  self.w_all = []\n",
        "  self.err_all = []\n",
        "  mini_batch_id = 0\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    shuffled_indices = np.random.permutation(X.shape[0])\n",
        "    X_shuffled = X[shuffled_indices]\n",
        "    y_shuffled = y[shuffled_indices]\n",
        "    for i in range(0, X.shape[0],batch_size):\n",
        "      mini_batch_id += 1\n",
        "      xi = X_shuffled[i:i+batch_size]\n",
        "      yi = y_shuffled[i:i+batch_size]\n",
        "      self.w_all.append(self.w)\n",
        "      self.err_all.append(self.loss(xi,yi,0))\n",
        "\n",
        "      grad = (2/batch_size) * self.calculate_gradient(X,y,reg_rate)\n",
        "      lr = self.learning_schedule(mini_batch_id)\n",
        "      self.w = self.update_weights(grad,lr)\n",
        "  return self.w\n",
        "\n",
        "def sgd(self, X:np.ndarray, y:np.ndarray, num_epochs:int, reg_rate:float):\n",
        "  ''' Estimates parameter of linear regression model using Stochastic GD\n",
        "      Args:\n",
        "        X: feature matrix\n",
        "        y: label vector\n",
        "        num_epochs: number of iterations\n",
        "        reg_rate: rate of regression\n",
        "      Returns:\n",
        "        weight vector: final weight vector\n",
        "  '''\n",
        "  self.w = np.zeros(X.shape[1])\n",
        "  self.w_all = []\n",
        "  self.err_all = []\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    for i in range(0, X.shape[0]):\n",
        "      random_index = np.random.randint(X.shape[0])\n",
        "      xi = X[random_index:random_index+1]\n",
        "      yi = y[random_index:random_index+1]\n",
        "\n",
        "      self.w_all.append(self.w)\n",
        "      self.err_all.append(self.loss(xi,yi,0))\n",
        "\n",
        "      grad = 2 * self.calculate_gradient(X,y,reg_rate)\n",
        "      lr = self.learning_schedule(epoch *X.shape[0] + i)\n",
        "      self.w = self.update_weights(grad,lr)\n",
        "  return self.w\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "1Vuq9hlF2oEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title [polynomial transformation]\n",
        "def get_combinations(x, degree):\n",
        "  return itertools.combinations_with_replacement(x, degree)\n",
        "\n",
        "def compute_new_feature(items):\n",
        "  return functools.reduce(lambda x, y: x*y, items) \n",
        "\n",
        "def polynomial_transform(x, degree, logging=False):\n",
        "  #convert feature to matrix\n",
        "  if(x.ndim ==1):\n",
        "    x = x[:,None]\n",
        "  x_t = x.transpose()   # transpose of feature matrix\n",
        "  features = [np.ones(len(x))] # populates 1's as first feature of each example\n",
        "  if(logging):\n",
        "    print('Input: ',x)\n",
        "\n",
        "  for degree in range(1, degree + 1):\n",
        "    for items in get_combinations(x_t,degree):  # generate combinations \n",
        "      features.append(compute_new_feature(items))  # combine features into new feature\n",
        "      if(logging):\n",
        "        print(items, ' : ', compute_new_feature(items))\n",
        "  if(logging):\n",
        "    print(np.asarray(features).transpose())\n",
        "  return np.asarray(features).transpose()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "owuWjnV33l9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title [create non linear training set]\n",
        "def non_linear_training_set(func, sample_size, std):\n",
        "  x = np.linspace(0,1,sample_size)\n",
        "  y = func(x) + np.random.normal(scale=std,size=x.shape)\n",
        "  return x, y\n",
        "\n",
        "def nonlin(x):\n",
        "  return np.sin(2 * np.pi * x)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "yprzM5sk3vvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title [model selection]\n",
        "def convert_dict_to_df(w_dict, degree):\n",
        "  poly_w_dict = {i:np.array(np.zeros(degree)) for i in range(degree)}\n",
        "  for deg in poly_w_dict:\n",
        "    weight_vector = w_dict[deg]\n",
        "    for i in range(len(weight_vector)):\n",
        "      poly_w_dict[deg][i] = weight_vector[i]\n",
        "    \n",
        "  poly_w_df = pd.DataFrame(poly_w_dict)\n",
        "  poly_w_df.columns = ['w_'+str(i) for i in range(degree)]\n",
        "  return poly_w_df\n",
        "\n",
        "def plot_model_selection(training_errors, val_errors):\n",
        "  plt.plot(training_errors,'o-',mfc='none',mec='b',ms=10,label='training errors')\n",
        "  plt.plot(val_errors,'o-',mfc='none',mec='r',ms=10,label='velidation errors')\n",
        "  plt.legend()\n",
        "  plt.xlabel('degree')\n",
        "  plt.ylabel('RMSE')\n",
        "  plt.show()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Wxoe6Z5w36Kf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title [plot model selection]\n",
        "training_errors = []\n",
        "val_errors = []\n",
        "w_dict = {}\n",
        "x_val = np.linspace(0,1,100)\n",
        "y_val = nonlin(x_val) +np.random.normal(scale=0.25,size=(len(x_val)))\n",
        "for i in range(10):\n",
        "  x_transform = polynomial_transform(x,i)\n",
        "  x_val_transform = polynomial_transform(x_val,i)\n",
        "  lin_reg = LinReg()\n",
        "  lin_reg.fit(x_transform,y,0)\n",
        "\n",
        "  w_dict[i] = lin_reg.w\n",
        "  training_errors.append(lin_reg.rmse(x_transform, y))\n",
        "  val_errors.append(lin_reg.rmse(x_val_transform, y_val))\n",
        "plot_model_selection(training_errors,val_errors)\n",
        "convert_dict_to_df(w_dict,10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "cellView": "form",
        "id": "PkEsSUQf4CZr",
        "outputId": "81b0110c-e63e-4936-cbb5-717a7d583153"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-a1a921cf3890>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnonlin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mx_transform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolynomial_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m   \u001b[0mx_val_transform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolynomial_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mlin_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinReg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Label Encoding:  \n",
        "Since the label y is a discrete quantity, we use one-hot encoding represent label.  \n",
        "For a binary classification,\n",
        "* The label 0 is represented with [1,0]\n",
        "* The label 1 is represented with [0,1]   \n",
        "The same scheme can be extended to the **multi-class setting**. In general, for a k-class set up, we use one hot encoding in k component vector. $[y_0,y_1,...,y_k]$. For label 1 <= r <= k, $y_r$ would be 1 and other components would be 0.  \n",
        "For 3-class set-up, \n",
        "* The label 0 is represented with [1, 0, 0]\n",
        "* The label 1 is represented with [0, 1, 0]\n",
        "* The label 2 is represented with [0, 0, 1]"
      ],
      "metadata": {
        "id": "cVPqyUka237L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LabelTransformer(object):\n",
        "  ''' Label encoder - decoder\n",
        "      Attributes:\n",
        "        n_classes: int\n",
        "          --> no of classes - k\n",
        "  '''\n",
        "  def __init__(self, n_classes:int=None):\n",
        "    self.n_classes = n_classes\n",
        "  \n",
        "  @property\n",
        "  def n_classes(self):\n",
        "    return self.__n_classes\n",
        "  \n",
        "  @n_classes.setter\n",
        "  def n_classes(self, K):\n",
        "    self.__n_classes = K\n",
        "    self.__encoder = None if K is None else np.eye(K)\n",
        "  \n",
        "  @property\n",
        "  def encoder(self):\n",
        "    return self.__encoder\n",
        "  \n",
        "  def encode(self, class_indices:np.ndarray):\n",
        "    ''' Encode class index into one-of-k code\n",
        "        Parameters:\n",
        "          class_indices: (N,) np.ndarray\n",
        "          non negative class index. elements must be integer in [0, n_classes]\n",
        "        Returns:\n",
        "          (N,K): ndarray - one-of-k encoding of input\n",
        "    '''\n",
        "    if self.n_classes is None:\n",
        "      self.n_classes = np.max(class_indices) + 1\n",
        "    return self.encoder[class_indices]\n",
        "  \n",
        "  def decode(self, onehot:np.ndarray):\n",
        "    ''' decode one-of-k class into class index\n",
        "        Parameters:\n",
        "          onehot: (N,K) np.ndarray - one-of-k code\n",
        "        Returns:\n",
        "          (N,) np.ndarray - class index\n",
        "    '''\n",
        "    return np.argmax(onehot,axis=1)  "
      ],
      "metadata": {
        "id": "j2URlBwm23oK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "binary_labels = LabelTransformer(2).encode(np.array([1,0,1,0]))\n",
        "binary_labels\n",
        "#LabelTransformer(2).decode(np.array([[1,0,1,0]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYKStq9lGAK6",
        "outputId": "5f4eb711-1582-4caa-9297-2bed9dc94437"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Least Square Classification Implimentation  \n",
        "## Training Data\n",
        "This representation of label has an impact on the learning set-up.\n",
        "* A feature matrix of shape (n,m) where n is the number of examples and m is the number of features\n",
        "* A label Matrix Y of shane (n,k) where k is the number of class labels. This set up is similar to multi-label regression.\n",
        "## Model\n",
        "The label matrix is obtained by multiplication of feature matrix and weight matrix. After adding a dummy feature to feature matrix, its shape becomes (n,m+1).\n",
        "$$ Y_{(n,k)} = X_{(n,m+1)} W_{(m+1,k)}  $$\n",
        "There is one weight vector per output. Hence total number of parameters to be estimated = (m+1, k).  \n",
        "## Loss Function\n",
        "Loss Matrix of shape (k,k):\n",
        "$$ J(w) = \\frac{1}{2} (Y_{(n,k)} - X_{(n,m+1)} W_{(m+1,k)})^T (Y_{(n,k)} - X_{(n,m+1)} W_{(m+1,k)}) + \\frac{Œª}{2} W^TW  $$ \n",
        "$$ = \\frac{1}{2} (E)^T_{(k,n)}E_{(n,k)} + \\frac{Œª}{2} W^TW_{(k,k)} $$\n",
        "\n",
        "**Normal Equation:**\n",
        "There is almost no code change needed for the ***fit*** function that uses normal equation method for parameter or weight vector estimation.\n",
        "$$W = (X^TX + Œª I)^{-1} X^TY$$\n",
        "\n",
        "## Iterative Optimization (GD, MBGD, SGD)\n",
        "The gradient calculation ***calculate_gradient*** for iterative optimization is as follows:\n",
        "$$ \\frac{DJ(w)}{D(W)} = X^T(XW - Y) + ŒªW $$\n",
        "New value of W is calculated in vector form as:\n",
        "$$ W^{(new)} := W^{(old)} - Œ± \\frac{DJ(w)}{D(W)}  $$\n",
        "\n",
        "**Inference**\n",
        "The predict function for this classification function is expected to return a discrete quantity  \n",
        "* We return the class label for the largest value of linear combination of features among all classes\n",
        "\n"
      ],
      "metadata": {
        "id": "zsDK13yaLhQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LeastSquareClassification():\n",
        "  ''' LSC Model:\n",
        "        y: np.where(X@W >=0, 1, 0)\n",
        "        X: a feature matrix\n",
        "        w: weight vector\n",
        "        y: label vector\n",
        "  '''\n",
        "  def __init__(self):\n",
        "    self.t0 = 20\n",
        "    self.t1 = 100\n",
        "  \n",
        "  def predict(self, X:np.ndarray):\n",
        "    ''' Prediction of output label for a given input\n",
        "        Arguments:\n",
        "          X:feature matrix\n",
        "        Returns:\n",
        "          y: label vector\n",
        "    '''\n",
        "    # check to make sure that shapes are compatible\n",
        "    assert X.shape[-1] == self.w.shape[0], f\"X shape {X.shape} and w shape {self.w.shape} are not compatible\"\n",
        "    print('predict: ',np.argmax(X@self.w, axis=-1), 'y_hat: ',(X@self.w).shape)\n",
        "    return np.argmax(X@self.w, axis=-1)\n",
        "  \n",
        "  def predict_internal(self, X:np.ndarray) -> np.ndarray:\n",
        "    ''' Prediction of output label for a given input\n",
        "        Arguments:\n",
        "          X:feature matrix\n",
        "        Returns:\n",
        "          y: label vector\n",
        "    '''\n",
        "    # check to make sure that shapes are compatible\n",
        "    assert X.shape[-1] == self.w.shape[0], f\"X shape {X.shape} and w shape {self.w.shape} are not compatible\"\n",
        "    return X@self.w\n",
        "######################################################\n",
        "####             same as LinReg Class              ###\n",
        "######################################################\n",
        "  def loss(self, X:np.ndarray, y:np.ndarray, reg_rate:float):\n",
        "    ''' Calculates loss for a model based on known labels.\n",
        "        Args:\n",
        "          X: feature matrix\n",
        "          y: label vector\n",
        "          reg_rate: regularization rate\n",
        "        Returns:\n",
        "          Loss \n",
        "    '''\n",
        "    e = y - self.predict_internal(X)\n",
        "    return (1/2) * np.transpose(e)@e\n",
        "    # return (1/2) * np.transpose(e)@e + (reg_rate/2)*np.transpose(self.w)@self.w\n",
        "  \n",
        "  def rmse(self, X:np.ndarray, y:np.ndarray):\n",
        "    ''' Calculates root mean squared error of prediction w.r.t actual label\n",
        "        Args:\n",
        "          X: feature matrix\n",
        "          y: label vector\n",
        "        Returns:\n",
        "          Loss\n",
        "    '''\n",
        "    return np.sqrt((2/X.shape[0])* self.loss(X,y,0))\n",
        "  \n",
        "  def fit(self, X:np.ndarray, y:np.ndarray, reg_rate:float):\n",
        "    ''' Estimate parameters of linear regression model w.r.t known labels.\n",
        "        Args:\n",
        "          X: feature matrix\n",
        "          y: label vector\n",
        "          reg_rate: rate of regression\n",
        "        Returns:\n",
        "          weight vector\n",
        "    '''\n",
        "    self.w = np.zeros(X.shape[1])\n",
        "    eye = np.eye(np.size(X,1))\n",
        "    self.w = np.linalg.solve(reg_rate*eye + X.T@X, X.T@y)\n",
        "    return self.w\n",
        "  \n",
        "  def calculate_gradient(self, X:np.ndarray, y:np.ndarray, reg_rate:float):\n",
        "    ''' Calculates the gradient of loss function w.r.t weight vector\n",
        "        Args:\n",
        "          X: feature matrix\n",
        "          y: label vector\n",
        "          reg_rate: rate of regression\n",
        "        Returns:\n",
        "          gradient vector\n",
        "    ''' \n",
        "    y_hat = self.predict_internal(X)\n",
        "    print('Calculate_gradient:',y_hat.shape, y.shape)\n",
        "    grad = np.transpose(X) @ (y_hat - y) + reg_rate * self.w\n",
        "    #grad = np.transpose(X) @ (self.predict_internal(X) - y) + reg_rate * self.w\n",
        "    return grad\n",
        "  \n",
        "  def update_weights(self, grad:np.ndarray, lr:float):\n",
        "    ''' updates the weights based on the gradient of loss function\n",
        "        w_new = w_old - lr * grad\n",
        "       Args:\n",
        "          grad: gradient of loss w.r.t w\n",
        "          lr: learning rate\n",
        "        Returns:\n",
        "        updated weight vector\n",
        "    '''\n",
        "    w_new = self.w - lr * grad\n",
        "    return w_new\n",
        "\n",
        "  def learning_schedule(self, t):\n",
        "    return (self.t0/(t + self.t1))\n",
        "\n",
        "  def gd(self, X:np.ndarray, y:np.ndarray, num_epochs:int, lr:float,reg_rate:float):\n",
        "    ''' Estimates parameter of linear regression model using gradient descent\n",
        "      Args:\n",
        "        X: feature matrix\n",
        "        y: label vector\n",
        "        num_epochs: number of iterations\n",
        "        lr: learning rate\n",
        "        reg_rate: rate of regression\n",
        "      Returns:\n",
        "        weight vector: final weight vector\n",
        "    '''\n",
        "    self.w = np.zeros(X.shape[1])\n",
        "    self.w_all = []\n",
        "    self.err_all = []\n",
        "    for i in np.arange(0, num_epochs):\n",
        "      self.w_all.append(self.w)\n",
        "      self.err_all.append(self.loss(X,y,0))\n",
        "    \n",
        "      grad = self.calculate_gradient(X,y,reg_rate)\n",
        "      self.w = self.update_weights(grad,lr)\n",
        "    return self.w\n",
        "\n",
        "  def mbgd(self, X:np.ndarray, y:np.ndarray, num_epochs:int, batch_size:int, reg_rate:float):\n",
        "    ''' Estimates parameter of linear regression model using MBGD\n",
        "     Args:\n",
        "        X: feature matrix\n",
        "        y: label vector\n",
        "        num_epochs: number of iterations\n",
        "        batch_size: number of examples in a batch\n",
        "        reg_rate: rate of regression\n",
        "      Returns:\n",
        "        weight vector: final weight vector\n",
        "    '''\n",
        "    self.w = np.zeros(X.shape[1])\n",
        "    self.w_all = []\n",
        "    self.err_all = []\n",
        "    mini_batch_id = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "      shuffled_indices = np.random.permutation(X.shape[0])\n",
        "      X_shuffled = X[shuffled_indices]\n",
        "      y_shuffled = y[shuffled_indices]\n",
        "      for i in range(0, X.shape[0],batch_size):\n",
        "        mini_batch_id += 1\n",
        "        xi = X_shuffled[i:i+batch_size]\n",
        "        yi = y_shuffled[i:i+batch_size]\n",
        "        self.w_all.append(self.w)\n",
        "        self.err_all.append(self.loss(xi,yi,0))\n",
        "\n",
        "        grad = (2/batch_size) * self.calculate_gradient(X,y,reg_rate)\n",
        "        lr = self.learning_schedule(mini_batch_id)\n",
        "        self.w = self.update_weights(grad,lr)\n",
        "    return self.w\n",
        "\n",
        "  def sgd(self, X:np.ndarray, y:np.ndarray, num_epochs:int, reg_rate:float):\n",
        "    ''' Estimates parameter of linear regression model using Stochastic GD\n",
        "      Args:\n",
        "        X: feature matrix\n",
        "        y: label vector\n",
        "        num_epochs: number of iterations\n",
        "        reg_rate: rate of regression\n",
        "      Returns:\n",
        "        weight vector: final weight vector\n",
        "    '''\n",
        "    self.w = np.zeros(X.shape[1])\n",
        "    self.w_all = []\n",
        "    self.err_all = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "      for i in range(0, X.shape[0]):\n",
        "        random_index = np.random.randint(X.shape[0])\n",
        "        xi = X[random_index:random_index+1]\n",
        "        yi = y[random_index:random_index+1]\n",
        "\n",
        "        self.w_all.append(self.w)\n",
        "        self.err_all.append(self.loss(xi,yi,0))\n",
        "\n",
        "        grad = 2 * self.calculate_gradient(X,y,reg_rate)\n",
        "        lr = self.learning_schedule(epoch *X.shape[0] + i)\n",
        "        self.w = self.update_weights(grad,lr)\n",
        "    return self.w"
      ],
      "metadata": {
        "id": "OlhR2u_wF__0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Least Square Classification Setup:\n",
        "1. Linearly separable binary classification setup.\n",
        "2. Linearly separable binary classification setup with a few outlier points.\n",
        "3. Multi-class classification with k=3.\n",
        "4. Polynomial least squares classification.\n",
        "\n",
        "Create a sample datasetfor binary classification with no of samples n=50.\n",
        "* It also has the facility to add outlier to generated dataset.\n",
        "* It can generate samples from multiple classes (>2).\n"
      ],
      "metadata": {
        "id": "AkdiKJA30SK9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.core.multiarray import concatenate\n",
        "#@title [create toy dataset]\n",
        "def create_toy_data(add_outliers=False,add_class=False):\n",
        "  x0 = np.random.normal(size=50).reshape(-1,2) - 1\n",
        "  x1 = np.random.normal(size=50).reshape(-1,2) + 1\n",
        "  if add_outliers:\n",
        "    x_1 = np.random.normal(size=10).reshape(-1,2) + np.array([5., 10.])\n",
        "    return np.concatenate([x0,x1,x_1]), np.concatenate([np.zeros(25),np.ones(30),]).astype(int)\n",
        "  if add_class:\n",
        "    x2 = np.random.normal(size=50).reshape(-1,2) + 2\n",
        "    return np.concatenate([x0, x1, x2]), np.concatenate([np.zeros(25), np.ones(25), 2+np.zeros(25)]).astype(int)\n",
        "  return np.concatenate([x0, x1]), np.concatenate([np.zeros(25), np.ones(25)]).astype(int)"
      ],
      "metadata": {
        "id": "dIwNkATcFd8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample1 = create_toy_data()\n",
        "sample2=create_toy_data(add_outliers=True)\n",
        "sample3=create_toy_data(add_class=True)\n",
        "sample4 = create_toy_data(add_outliers=True, add_class=True)\n",
        "print(sample1[0][:5])\n",
        "print(sample2[0][:5])\n",
        "print(sample3[0][:5])\n",
        "print(sample4[0][:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49WToFgdH89f",
        "outputId": "6cf96493-ae47-4d0d-ad1d-16edad155b0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.50726948 -1.25582697]\n",
            " [-0.48481253  0.53908622]\n",
            " [ 0.81045182 -0.25130705]\n",
            " [-0.96645568 -1.37668556]\n",
            " [-1.52664992 -1.19592317]]\n",
            "[[ 0.14157733 -1.75079347]\n",
            " [ 0.13373891 -0.05043549]\n",
            " [-0.37831757 -2.48928746]\n",
            " [-2.12493464 -3.09027953]\n",
            " [ 0.00321596  0.6084744 ]]\n",
            "[[-2.15630609  0.38934832]\n",
            " [-2.57137657 -1.41288205]\n",
            " [-0.42742697 -1.53641783]\n",
            " [-1.46044661 -2.72407562]\n",
            " [-1.25664772 -2.00107278]]\n",
            "[[ 0.06664937 -1.31735615]\n",
            " [-0.7507121  -1.80746791]\n",
            " [-1.14960477 -0.37457466]\n",
            " [-0.04159817 -1.42790168]\n",
            " [-0.12855715 -1.18466524]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Preprocessing Steps:\n",
        "1. Generate synthetic data by calling create_toy_data function\n",
        "2. Perform polynomial transformation(default degree=1) on feature set.\n",
        "3. Divide the data set into Train and evaluation sets with train_test_split api from sklearn library\n",
        "4. Perform Label transformation for both train and test sets."
      ],
      "metadata": {
        "id": "jNqr3joWKi-L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title [Data Preprocessing]\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def preprocess(add_class=False,add_outliers=False,degree=1):\n",
        "  x, y = create_toy_data(add_outliers,add_class)\n",
        "  x_poly = polynomial_transform(x, degree=degree)\n",
        "  x_train, x_test, y_train, y_test = train_test_split(x_poly, y)\n",
        "  y_train_trans = LabelTransformer().encode(y_train)\n",
        "  y_test_trans = LabelTransformer().encode(y_test)\n",
        "  return x_train, x_test, y_train, y_test, y_train_trans, y_test_trans  "
      ],
      "metadata": {
        "id": "9ZCVqy2DFCYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title [model visualization]\n",
        "sns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\n",
        "\n",
        "def visualize_model(x_train, labels, lsc_obj, degree=1):\n",
        "  f = plt.figure(figsize=(8,8))\n",
        "  \n",
        "  #compute xlim and ylim\n",
        "  x1_min = np.min(x_train[:,1])\n",
        "  x1_max = np.max(x_train[:,1])\n",
        "  x2_min = np.min(x_train[:,2])\n",
        "  x2_max = np.max(x_train[:,2])\n",
        "  x1_test, x2_test = np.meshgrid(np.linspace(x1_min, x1_max, 100), np.linspace(x2_min, x2_max, 100))\n",
        "  x_test = np.array([x1_test, x2_test]).reshape(2,-1).T\n",
        "  x_test_poly = polynomial_transform(x_test, degree=degree)\n",
        "  y_test = lsc_obj.predict(x_test_poly)\n",
        "\n",
        "  print(y_test.shape)\n",
        "\n",
        "  sns.scatterplot(data=x_train, x=x_train[:,1], y=x_train[:,2], hue=labels)\n",
        "  plt.contourf(x1_test, x2_test, y_test.reshape(100,100),alpha=0.5, levels=np.linspace(0,1,3))\n",
        "  plt.xlabel('x1')\n",
        "  plt.ylabel('x2')\n",
        "  plt.xlim(x1_min, x1_max)\n",
        "  plt.ylim(x2_min, x2_max)\n",
        "  plt.gca().set_aspect('equal',adjustable='box')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "wTzP16EinGMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Linearly Separable binary classification"
      ],
      "metadata": {
        "id": "Op0SYEJFqcDG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x1_train, x1_test, y1_train, y1_test, y1_train_trans, y1_test_trans = preprocess()\n",
        "print('shape of training feature matrix', x1_train.shape)\n",
        "print('shape of training label vector', y1_train.shape)\n",
        "\n",
        "print('shape of test feature matrix', x1_test.shape)\n",
        "print('shape of test label vector', y1_test.shape)\n",
        "print(y1_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mClPcXHZqYAa",
        "outputId": "eee1a400-adbe-4a48-f05a-ee34a2aa54d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of training feature matrix (37, 3)\n",
            "shape of training label vector (37,)\n",
            "shape of test feature matrix (13, 3)\n",
            "shape of test label vector (13,)\n",
            "[1 0 0 1 1 1 0 0 1 0 1 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualize the dataset:**"
      ],
      "metadata": {
        "id": "mKFs3cuZrvJD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_style(\"white\")\n",
        "f = plt.figure(figsize=(8,8))\n",
        "sns.set_context(\"notebook\",font_scale=1.5, rc={\"lines.linewidth\":2.5})\n",
        "sns.scatterplot(data=x1_train, x=x1_train[:,-2], y= x1_train[:,-1],hue=y1_train)\n",
        "plt.xlabel('x1')\n",
        "plt.ylabel('x2')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "id": "QBNPZBQfry9e",
        "outputId": "0e823c94-0116-461c-bf82-86a4571a0832"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lsc = LeastSquareClassification()"
      ],
      "metadata": {
        "id": "uM1L3eijsvX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normal Equation:"
      ],
      "metadata": {
        "id": "dfEzLbPBs1WJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lsc.fit(x1_train, y1_train_trans, reg_rate=0)\n",
        "print('weight vector:', lsc.w)\n",
        "#print(x1_train)\n",
        "#print(y1_train)\n",
        "visualize_model(x1_train,y1_train, lsc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "vfYTbe3Rs3up",
        "outputId": "649d2bab-8fad-403e-cbbd-1069e20fb19a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weight vector: [[ 0.5324894   0.4675106 ]\n",
            " [-0.17485051  0.17485051]\n",
            " [-0.18151776  0.18151776]]\n",
            "predict:  [0 0 0 ... 1 1 1] y_hat:  (10000, 2)\n",
            "(10000,)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhQAAAFvCAYAAAASd1J6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXiU9b028DuzJ5nsmQTCEkwMCYIBiUABPS8C1UCjLAJWhRSxWo6CLep7gNP6nuNSYwWPpSrHYlEg4AIFjNWKG7S1NCyFQAwJgQ5LgJBkSCDJJJl93j/GDBkm+yzPPDP357q8yvzmeZ58k0Jy57eG2e12O4iIiIg8IBG6ACIiIhI/BgoiIiLyGAMFEREReYyBgoiIiDzGQEFEREQekwldgFgZDAaUlZVBo9FAKpUKXQ4REZFPWa1W6HQ6jBo1CiqVyu19Bop+Kisrw8MPPyx0GURERH61bds23H777W7tDBT9pNFoAABL71uCGHWMwNVQb5ltNpRXN+Fo1TXADsilYZh2SxIGRof3+5mp1nMAgLSxw71UJRFR4KlpaMTi37zt/Pl3IwaKfmof5ohRxyA+Ok7gaqgvEqLjMHJICtpMVsSEyxEbIffoec1w/P+vP30aAJA5cZTHNRIRBaquhvk5KZNCjkwiQVKUEqkJER6HiY60sgwAQGVxmdeeSUQkFgwURF7UMVQwWBBRKGGgIPIyrSyDvRVEFHIYKIh8pD1UEBGFAgYKIiIi8hhXefiYMi4cCelJkCr4pbaaLKjX1sF4tU3oUoiIyMv4U86HlHHhGDByMAYOSIFCLkdYWJjQJQnGbrfDZDZDrlKg5sTFkAoV7fMouJyUiIIZhzx8KCE9CQMHpECpUIR0mACAsLAwKBUKDByQgoT0JKHL8RtO0CSiUMFA4UNShQwKuff2OQgGCrk8JId/uJyUiIIdA4WPhXrPxI1C+evB3goiCmYMFER+xlBBRMEo9PqeiQKAc48KTtgkoiDBHgoiAbG3goiCBXsoqF9MJhM2bHwHe77cg+bmJtx8cwaWPvYzjMsZJ3RposPeCiIKBuyhoH55seAlfLjjQ9xz9z1Y8dQKSMLCsOL/Po3vyr4TujTRYm8FEYkZAwX12YnyE/jqm6+wbOmTWP7vyzD7vtl487dvYkByMt56e73Q5Ykaz/8gIrFioKA+2/vXfZDJZLgv7z5nm1KpxL0/uhfHvzuOK1euCFgdEREJQZRzKOrq6rBlyxYcP34cZWVlaG1txZYtWzBhwoQe7121ahV2797t1j569Ghs377dF+UGnVOnTyF1aCoiIiJc2m8ZcQvsdjtO/es0EhMTBaqOiIiEIMpAcfbsWbzzzjtITU1FZmYmSkpK+nR/eHg4nn/+eZe2+Ph4b5boM3+u0OHN/VWoaTZhQJQCyyYPxcwRGr/WUF9fD02i+8dMTHCEiCtXdH6tJxjx/A8iEhtRBoqRI0fiwIEDiIuLw9dff40nn3yyT/fLZDLMmjXLR9X5zp8rdHjx6zMwWGwAgMvNJrz49RkA8GuoMBqNkHeypbhCoXC+T/3XPo8i3XIalcVlDBVEJAqinEOhVqsRFxfn0TOsViv0er2XKvKPN/dXOcNEO4PFhjf3V/m1DqVSCbPZ7NZuMpmc75PneP4HEYmJKAOFp1paWpCTk4OcnBxMmDABBQUFovituqbZ1Kd2X0lISMCVeveJl+1tiZ0Mh1D/8PwPIhILUQ55eEKj0eCnP/0pRowYAZvNhn379mHTpk3QarX4wx/+IHR53RoQpcDlTsLDgCiFX+sYfnMGPvrjdrS2trpMzDxRfgIAkHHzzX6tJxRoZRnOIRCAcyuIKPCEXA/FM888g2eeeQYzZ85EXl4eXnvtNTz66KP49ttvsX//fqHL69ayyUOhkrn+X6aSSbBs8lC/1nHXlKmwWCz45NNPnG0mkwmf/vkzZN+a3emETfIceyuIKJCFXKDozJIlSwAAxcXFAlfSvZkjNHhuehoGRikQBmBglALPTU/z+yqPUbeMxLS7puLNt9/Cm//7Fj7+5GM8+YtlqKmtwZNLn/BrLaGIm18RUSAKuSGPziQmJkIul6OxsVHoUno0c4TG7wGiM//vP/8fNmzcgM+/+BzN+mbcnJaO/3n1NYy+dbTQpRERkQAYKADU1NTAbDaLZi+KQKBUKrH8ieVY/sRyoUshIqIAENRDHlVVVaiqur6k0mg0drpUdP16x/kTd9xxh99qI/IU51EQUSARbQ9FewjQarUAgKKiIhw5cgTR0dFYuHAhAGDx4sUAgL179wIAdDod5syZg7y8PKSlpTlXeRQXF2PmzJkYN45Hb5M48MhzIgo0og0U69atc3m9c+dOAMCgQYOcgeJG0dHRmDJlCvbv34/du3fDZrNh2LBhWLVqFfLz831eM5G3dVxOylBBotZSD7TVA1IFEKkBFJFCV0R9JNpAUVlZ2eM17T0T7aKjo7FmzRpflUQkCPZWkOg1XgRKPwKs3+/AG58OZOYCyihh66I+Ceo5FEShhHtUkChZjID2L9fDBAA0aIHmy4KVRP0j2h4KInLH3gofs5odP+iaqh1d8tGDgAiuDvOIxQi01rm3G8V11hIxUBAFpfa5FeRlDVrgxMfXX6tigdEPAOGeHVYY0hSRQMJwoPaGnrWIBGHqoX7jkAcRUW+YWgHtPtc2wzWguUaYeoKFRAqkTgTibnK8lsqBjB8CUQOErYv6jD0URES9YbcAljb39o5j/8HCbAAsBkAR4Vh14WsRCcDIOYCxEZDIHD0/YWG+/7jkVeyhIApinKDpRYooICXHtS1MAqiF3wrfq65dAI69Dxx62zG8o9f55+PKvl8uGh7HMCFS7KEgClI88tzLwsKAlNsAqQyoPgYoY4Cb7gTUQdQ131oPfLf9eq9LwxnA1AKM/jEgDxe2Ngp4DBREQax91Qc3v/ISVTSQOhkYeJuja17mh+EAf2q76j6Eo68FDI0MFNQjBgrqlytXruCjP27HiYoTOHnyJFrbWvHWureQc9tYoUsLKm0mK3R6I4wWK+IiFEiIVParN5i9FV6miBC6At+QqdzbpDL/zKMg0eMcCuqX8xeqUPh+Ierq6pCeni50OUGp1WTB1xW12H30Ev5cWoMPDlXhQkNrv5+nlWVw8yvqXkQiMOBW17a0u7gsNlDoa4FLR4FLRwJydRF7KKhfsjIz8cWf9iAmJgZ//favWPnLVUKXFHTqmo04o2txvrbZgL2VdXjg9iEIV0j7/VzRnP/Rdg1oa/j+bIfEzn97Ju+Sq4C0KUDSCMCkB1RxgDqZkyQDQdNl4Pj714ekJDJgzIOOzdUCBAMF9UtkBA/u8bU2k9WtrbHNDJPVhnD0P1AAIthRs+myY3Kg+ftlmskjgfS7AIVa2LpCgSISiE8Tugq6UV256/wWmwWoPh5QgYJDHkQBKi7Cfdw6LTESkQrv/R4QkEMgFhNw5i/XwwQA1J4AmgKvi5fIK6wW4FqV4+/9hYOAvpdbkRubAbvd5+X1FnsoREZ+6mOEH1wLib4aNnUK2iY8C/Pw2UKXRT6giVIid9QA/KWyDgazDUPjIzD55kTIpN7tfg643gqLofODoYxN/q+FyB+unQO+++P117JiYMzDrnucJI8EdBWu96WMDqjhKAYKEZGf+hiRf/1PhH2/W59UfwmRf/1PtAAMFUFIKglD5oAoDIoNh8lqQ5RKBrnUd52KATO3Qh7h6HLXnXRtD+chXBSELEbg7N9vaDMAjVWugSJ2CDDiPuDc3wHYgdRJQOwwf1baIwYKEQk/uNYZJtqFWdoQfnAtA0UQU6v89880IA4Vk8qAYZMdEzL1dY7dKFMn82wHCk52O2A1urffuB+ITAkk3/L9/BZ7QO4LwkAhIhJ9dZ/aiUQrUgOMftCx0kMqdyxblHg2EZUoIMlVwJAJwKk919vCwoCYIV1fH6AYKETEpk6BVH+p03aioCMPD8jfwqgDU6vjhx//f/JM4nBHT9zFfzo2TRs6EYgaKHRVfcZAISJtE551mUMBAHZZONomPCtgVRSMuKNmiDG1AtfOA3UVjj0/NFmAOqnr681twJVTwPliR6AYdieQkO7olqe+U0QAA7MdX3eJxLHHhAiJs+oQZR4+Gy1AwKzyeHfzewCAc+fPAQD2fPE5jpceR5Rajfn3zxekJvIcz/8IQbVlgHav489XTgHVJcBti4CILibCXj0HVH5+/XXFJ8Ct8x2hgvpP5GfDiDJQ1NXVYcuWLTh+/DjKysrQ2tqKLVu2YMKECb26X6vV4uWXX8bRo0chl8tx1113YeXKlYiPD/xZ5ObhswNmAuaGjRtcXv/pz58CAAYMGMBAEQR4/keIMDQB5/e7tpnbHNs8dxYo7DZH4LhRXTkDRYgTZaA4e/Ys3nnnHaSmpiIzMxMlJZ385e5CTU0NHn74YURHR2PFihVobW3Fu+++i1OnTmH79u2Qy+U+rDy4HPhbsdAlkI+xtyJE2G19uDgMUEa5N3fWRiFFlIFi5MiROHDgAOLi4vD111/jySef7PW9b7/9NoxGIwoLC5GcnAwAyM7OxiOPPIKioiLMmzfPV2UTiRZ7K4KYMsoxCfDs3663yVVAZBdzKMLCgEFjHfuE2L7fHl6qcIz/U0gTZaBQq/u/n/+XX36JqVOnOsMEAEyaNAnDhg3D559/zkBB1AX2VgSpsDBg4GhHsKj5zrFkd8CtQGRC1/dEpTjmWDRVO+6PHtT9JE4KCaIMFP1VW1uL+vp6jBrl/o0wOzsb+/fv7+QuIuooIDa/Iu9SRDpCRPKo3m3lHBbm2GiMm41RByF1OFhdnePAFY1G4/aeRqNBfX09rFb3Ex6JiEJCAJ0LQeITUoHCaHRsb6pQuC/NUSod66cNBoNfayIiIgoGIRUo2kODyWRye689bKhUgbutKVEgCagjz4lIcCE1hyIpyTFpSKfTub2n0+mQkJAAqdS75wXY7XaEsRvRyW63C10CeUHAHXlO4mezAU2XgLoTjj8PGOWY7MkzXEQjpHookpOTER8fj7Iy99+sSktLMWLECK9+PKvJApPZ3POFwcYOWKw2GMxWmCw2lxBhMpthNVkELI68qT1YsLeCPNZ0CTj+PlB9DKgpdfy58aLQVVEfBHWgqKqqQlVVlUvb3Xffjb1796K2ttbZVlxcjHPnziE3N9erH79eW4fLNdUwmkwh9Zu50WJFQ4sJTW1mXGs1odlggc1mg9FkwuWaatRr64QukbxIK8uAVpaByuIyBotgY7M4ds30x/ev2hOuH8cOx46cIfS9U+xEO+Sxfv16AI5ttAGgqKgIR44cQXR0NBYuXAgAWLx4MQBg7969zvuWLl2KPXv2ID8/HwsXLkRrays2btyIrKwszJo1y6s1Gq+2oebERZgNJkgVov1S94nNDrQaLbjxW0C4XIowqxX12joYr7Z1ei+JW8fNrzgEEgSaLwPnDwD6GiBphGOvivA43328znbrtHlp1Z31+55iKXdC9iXR/pRbt26dy+udO3cCAAYNGuQMFJ0ZOHAgtm7dildeeQWvvfYa5HI5pkyZgtWrV3e6+sNTxqttqP7nea8/N1DV603YesD98/1R9kDcnNT/DclIHDi3Iki0NgDHPwIs3696qzoAtF4FRuT57ody8kigthQuv40Mus2zpawWI9BwFrhw0DEXY+hEIHYog4WPiDZQVFZW9nhNx56JjjIyMrBx40Zvl0QA1CopkmOUqG00OtskYUBsBP8BhxL2Vohca/31MNHuSiVguNNxvLkvxAwGsh8ELh119FYMGuto88S180D5x9dff7cDGP0gEJfq2XOpU6INFBSYlDIpfjgiGftO6nDpWhvUKhmmjUhCQqRS6NLIz3j+h4hJOvnRIJH5dsWFROr4QR871PHa09VxNhtw8Yh7e105A4WPMFCQ1yWolbhvTApaTBYopBJEKvnXLFTx/A+RitQ4lmw2XbreNmwyoIr1/cf21jL7sDBA1sm+QjL+cuMr/E5PPqGQSaCQeX9OCokTz/8QGaUaGHEf0HgBaGsAolMcAUNMe+qEhQGDc4D6U9dXikikPBXVhxgoiIgCnVHvmA9w5V9A9EAg4WYgIt63HzM8xvGfmEUPBsYsBBq0QJgUiE/jgWb9ZTYAzTXdXsJAQUQUyGxWxyqFi4cdr3UVwOVSYPQDjiPHqWsSCRAzyPEf9Z+pBdDuA7THu72MgYKI/EIry+By0v5ouwpc+qdrW+sVoEXHQEH+0VwD1Pa8aV1Q75RJRIGFW3X3Vye7RXIHSfIXY3OvLmOgICK/6hgqGCx6QRULJN/q2qaM8t1+EEQ3Cu/d6h4GCiLyu/bzPwD2VvRIKgOG3QHcPN2x2mLIeCB7AaAS+YRJEo+ogUDa/3HMSekGAwURCYahopdUMcDg24ExDwPpUx37RBD5i0wJDJ4AjFrQ/WV+KoeIqFM8/6MPfLlTJVF3JBIgovvD4dhDQUQBgb0VROLGQEFEAcPZW0FEosMhDyIiEpa5DWi8CDScASISgPibHP9LosJAQUQUgMwWK+r1JrSZrYgJlyMuUoEwMZ2l0Vt2O1DzHaDde71NFQuMeZArWUSGgYKIAgp31ARMZisOnKlHyYVrAACpJAz3ZqcgNTFS4Mp8wNgEnPu7a5vhGqCvY6AQGc6hIKKAE+oTNHV6ozNMAIDVZsfXFbVoNVoErMpH7DbA3snnZbP6vxbyCAMFEQWkUN5Rs9Xk/sNUb7TAYA7CH7LKaGDgWNc2mRJQc68NsWGgIKKAFao7asaEy4EbpkskRSkRqQzCUWqJ1LH7Z/pUIDIJSB4JjH6QkzJFKAj/dhJRsNHKMpBuOe0MFcE+tyJBrUDuLQOwt7IOJosNcREKTB+RDKU8SDe2UkU7QsXAMYBE1uMWzxSYRBkoTCYT1q1bh6KiIjQ1NSErKwsrVqzAxIkTu73vjTfewJtvvunWnpiYiP379/uqXCLygvaeivZgEcyhQiqRIHNgNAbGqGC02KBWyRCuEOW3676RKYSugDwgyr+hq1atwpdffon8/HykpqZi9+7deOyxx1BYWIjbbrutx/tfeOEFqFQq5+uOfyaiwNbeWxEKoiP4A5bEQ3SBorS0FJ999hlWr16NxYsXAwBmz56NvLw8rF27Ftu2bevxGTNmzEB0dLSPKyUiIgodohuo2rNnD+RyOebPn+9sUyqVmDdvHo4cOYK6uroen2G326HX62G3231ZKhERUcgQXaCoqKjATTfdhMhI1w1esrOzYbfbUVFR0eMzpkyZgpycHOTk5GD16tW4du1aj/cQUWAJpVUfRGIguiEPnU6H5ORkt3aNxrFmubseiujoaCxatAijR4+GXC7HgQMH8NFHH6G8vBw7duyAQsHxSiIx4JHnRIFHdIHCYDBALpe7tSuVSgCA0Wjs8t6f/OQnLq9zc3ORkZGBF154AR9//DEWLFjg3WKJyKc6LidlqCASluiGPFQqFcxms1t7e5BoDxa99eCDDyI8PBzFxcVeqY+I/Kt986tQ3FGTKJCILlBoNJpOhzV0Oh0AICkpqU/Pk0gkSE5ORmNjo1fqIyJhhOKOmkSBRHSBIisrC2fPnkVLS4tL+/Hjx53v94XZbMbly5cRFxfntRqJSBjsrSASjugCRW5uLsxmM3bs2OFsM5lM2LVrF8aOHeucsFldXQ2tVutyb0NDg9vzNm7cCKPRiDvvvNO3hROR37C3gsj/RDcpc/To0cjNzcXatWuh0+kwdOhQ7N69G9XV1SgoKHBet3LlShw6dAiVlZXOtrvuugszZ87E8OHDoVAocPDgQXzxxRfIyclBXl6eEJ8OEflIx5UgRqsNw3KyoFbKIZGEdX8jEfWL6AIFALz66qv47W9/i6KiIjQ2NiIzMxMbNmxATk5Ot/fde++9OHr0KPbs2QOz2YxBgwbhiSeewM9+9jPIZKL8UhBRN4wWK3Zd1mCI6RSOXTiAYWOzMDY1DmqV+0oxIvKMKH+KKpVKrFy5EitXruzymsLCQre2l156yZdlEVGAuXzNgL9U6gDE4aHUBpRcuAa1SoaxqfFCl0YUdEQ3h4KIqLeqGlrd2k5UN8FssQpQDVFwY6AgoqAVG+E+tJGoVkIq4bc+Im/jvyoiClpD4iNcQkWCrgZJDbWcmEnkAwwURBS04iIUmHNbCvJGaXAtMh1IGA61zM7lpEQ+IMpJmUREvRXdegHRlTsBuw0AoE24GemZtzhDBc8AIfIO9lAQUfAytQCnv3CGCQBA/b+g1au4+RWRlzFQEFHwspoBQ5N7u7kNAHfUJPImDnkQUfBSqIGEDKD+9PW2sDAg4vo+FB131AQ4BELUX+yhIKLgJZUB6VOAhHTHa4UauGU2EOl+KrEzWBBRv7CHgoiCW0SCI0QYmwGpAlCqha6IKCgxUBBR8JPKXYY5iMj7OORBRNQBJ2gS9Q97KIiIvscJmkT9xx4KIqIb9Hk5qc0KGFsAm8WHVREFNvZQEBF1QivLQLrldM87arbogKqDwNWzQOxQYOhEQO2+ioQo2LGHgoioC1pZRve9FaYW4EQRUFvm+HNdBVC207GihCjEMFAQEfWgY6hwCRZtV4HWK64XGxod7UQhhoGCKEC1GC24dLUNtU0GmCy2nm8gn+q0t0Ii7/xiCUeTKfTwbz1RALqiN+JPx6vR1OaY5HdLSjQm35yACAX/yQrNZW6F3YbMQWOBS0evX5A8yrGZFlGI4XcnogBjtdlx+NxVZ5gAgPLqJqRpIpGu4S6PgaC9pyLdchqVdRpkjrofaLkCRCYAUSmATClwhUT+J8ohD5PJhDVr1uCOO+5AdnY2FixYgOLi4l7dW1tbi5///Oe4/fbbMXbsWDzxxBO4cOGCjysm6j2jxYqLDa1u7Q0tJgGqoe5oZRmARI7K00YgdSKQOJxbe1PIEmWgWLVqFTZv3oz77rsPv/zlLyGRSPDYY4+hpKSk2/taWlqQn5+PI0eOYOnSpXjqqadQXl6O/Px8NDY2+ql6ou4pZVIMTYhwa0+I5G+9gYiHihE5iG7Io7S0FJ999hlWr16NxYsXAwBmz56NvLw8rF27Ftu2bevy3vfffx/nz5/Hrl27cMsttwAA7rzzTtx7773YtGkTfv7zn/vjUyDqllQShttT41HXZHT2SmQPjsGAGJXAlRERdU10PRR79uyBXC7H/PnznW1KpRLz5s3DkSNHUFdX1+W9X3zxBcaMGeMMEwCQnp6OiRMn4vPPP/dp3UR9kaBW4P6cwZh/+2A8NGEo7shIRIRCKnRZRERdEl2gqKiowE033YTIyEiX9uzsbNjtdlRUVHR6n81mQ2VlJUaNct/t7tZbb8W5c+fQ1tbmk5qJ+iNCIUVKbDg0UUrIpaL7pxpStLIM9z0qiEKM6L5L6XQ6JCW5b2ur0WgAoMseimvXrsFkMjmvu/Feu90OnU7n3WKJKGT0+fwPoiAjujkUBoMBcrn7ZjJKpWPCmtFo7PS+9naFQtHlvQaDwVtlElEI4mmlFMpE10OhUqlgNpvd2tsDQ3s4uFF7u8nkvvSu/V6VipPeiMhz7K2gUCS6HgqNRtPpsEb7cEVnwyEAEBsbC4VC0emwhk6nQ1hYWKfDIURE/cHeCgo1ouuhyMrKwtmzZ9HS0uLSfvz4cef7nZFIJBg+fDjKytx/YygtLUVqairCw8O9XzARhTT2VlCoEF2gyM3Nhdlsxo4dO5xtJpMJu3btwtixY5GcnAwAqK6uhlardbn3nnvuwbFjx1BeXu5sO3PmDA4cOIDc3Fz/fAJEFHK4+RWFAtENeYwePRq5ublYu3YtdDodhg4dit27d6O6uhoFBQXO61auXIlDhw6hsrLS2fbQQw9hx44dePzxx/HII49AKpVi06ZN0Gg0zk2y+qrNZPX0UyIiIhI90fVQAMCrr76KRYsWoaioCC+99BIsFgs2bNiAnJycbu9Tq9UoLCzE2LFjsX79eqxbtw5ZWVnYunUr4uLi+lXL3pN1aDa4TxIlIiIKJWF2u90udBFidPHiRUybNg1JqXNw79ibMTw5SuiSiChQWYxIt/0LkDiWrXOCJonRpSsNyF35G3zzzTcYPHiw2/ui7KEINHqjpeeLiCj02O3A1fPA8Q+hPfw1tOcvAlYjJ2hSUGKg8AJNFE+BJKJO6OuA0o+A5suAuQ24cBDa89UA7Nyqm4IOA4WHJqUnIDmaG2IRUSdarwB2m2tbzXFoLclcTkpBh4HCQ5kDoqDgwU1E1Bmp+1b/kEcAEscCu46hgsGCxI4/CYmIfEWdDETesHvvzdMAxfXTkrWyDPZWUFAQ3T4URESioYoGbr0faKoGzK2OgBE1oNNLtbIMpFtOo7K4jKtASJQYKIiIfEkV4/ivF3j+B4kZhzyIiAIMh0BIjHodKJqbm1FaWopLly51ec2FCxfw8ccfe6UwIqJQxvM/SGx6FSh+//vfY9KkSXjggQcwffp0LFq0CFVVVW7XlZSUYPXq1V4vkogCTIsOuHQEOF8MNF5yXxpJRCGnxzkU3377LV5//XUMGzYMd911Fy5fvoyvv/4ac+fOxfr16zF+/Hh/1ElEgaJFB5RsAywGx+uwMCD7ASBumKBlBTqb3Y56vQnX2syIUEiRqFZCKeOoMwWPHgPFu+++i/T0dOzatQtKpWNHyJMnT2LZsmV4/PHHsX79ekyaNMnnhRJRgLh6/nqYABzbS5//BxA9CJDKhasrQFxtNaGpzYxwhQzxkQrIJGEAAG1dCz4vu4z205PGDI3FxLQEKLoJFVpZBidokmj0GI//9a9/Ye7cuc4wAQBZWVnYvn07UlNT8e///u/4+9//7tMiiSiAdAwT7cytHPYAcL6+Be8frMLHJdX44FAVjlVdhdlqQ5PBjG9O1qLjUYzHqq7hit7Y4zM5QZPEosdAodfrERPjvuQpPj4eW7ZsQVpaGp588kn87W9/80mBRBRg4oY5hjk6GjwOkIX2mTZ6owVfnqiFxfp9arAD+/9Vj3q9CSaLDUaze+BqM1t79WzuqEli0GOgGDBgAM6ePdvpezExMdi0aRPS0tKwbNkyhgqiUBA1ELh1vmOIIyIByJwBJHJFQpvJilaTe0BoMVoQqZQhQe26DbckDIgJ7/0QEXfUpEDXY6AYM2YMvvnmmz1wXokAACAASURBVC7fbw8VN998Mz799FOvFkdEAUgiBeLTgNEPAGMXAQNHO86nCHGRSimiw2+YlhYGRIfLES6X4u6RA5AY5QgVEQopfpSdgoTIvvfqsLeCAlWPgWL69OnQ6/U4ePBgl9e0h4pbbrkF9o6DhEQUvKQKQMaTdttFKGS4Z+QARCilAACZNAw/vCUZ8ZGOEJEUpcT9Ywdj4Q9S8eD4oUjTRLqNHPUWeysoEPW4ymPatGmYNm1ajw+Kjo7Grl27vFIUEZEYpcSG48HxQ9FssEAllyAuwnWYQyWXQiWXeu3jtZ//QRQI+rQI+o033ui2B6KxsRFPPPGEx0UREYmVWinDwBiVW5ggCnZ9ChRvvfUW8vPzUVtb6/beoUOHcO+99/plYmZTUxOee+45/OAHP8CYMWOQn5+PioqKXt27atUqZGZmuv23YMECH1dNRJ6y2uyoazZCq9OjtskAi41LVYkCRZ9OG33++edRUFCA++67D7/+9a8xffp02Gw2/O53v8M777yD5ORkbN261Ve1AgBsNhsef/xxnDp1CkuWLEFcXBzef/99LFq0CLt27cLQoUN7fEZ4eDief/55l7b4+HhflUzkNVabHVJJPwfeRc5uB07WNOPrilrg+47SfxuuQfbgmJD9mrTjkecUCPoUKB544AGMHTsWK1aswPLlyzF//nycPn0aJSUluOeee/DSSy8hKirKV7UCAPbs2YOSkhK89dZbmD59OgBgxowZuOeee/Dmm2/i1Vdf7fEZMpkMs2bN8mmdRN6kN1qgrdOj4nITkqNVGDUoBpqo0Nr34WqrCftO1jnDBAB8e1qHIfHhSFSH1teiIx55ToGizxvJZ2RkYOfOnRgzZgx27NiBY8eO4emnn8a6det8HiYA4IsvvkBSUpLLRNH4+HjMmDEDX3/9Ncxmc6+eY7VaodfrfVUmkdfYbHYcOX8Vf6nUobbJiNKLjdhdcgnXWnv3dz1YGMxWWG2uc7jsdsf+D8QdNUl4fQ4UZrMZa9asQUlJCYYMGQKpVIqtW7fi0KFDvqjPTUVFBUaOHImwG9Zb3XrrrWhpaen0FNQbtbS0ICcnBzk5OZgwYQIKCgpgNPa8BS6REJoMFpReuObS1mayor4ltP7OqlUyqOSu37Lk0jBEqfrU0RrU2peTco8KEkKfAsXZs2exYMECbN26FQ8++CA+/fRTbNu2DXK5HI888gjWrVsHm48nSel0OiQlJbm1t7fV1dV1e79Go8FPf/pTvPzyy3jttddwxx13YNOmTXjyySd9Ui+Rp8LC4BagHe2hNW8gWiVHXnaKM0BEKKXIG52CWK6mcMPeChJCn6L93LlzIZfL8cYbb+CHP/whAGD06NEoKirCc889h//93//FoUOHsG3btl49z2az9XqIov1wMoPBAIXC/RtIe5vB0MnBRR0888wzLq/z8vKQnJyMjRs3Yv/+/Zg8eXKv6iHyl2iVHONuisMBbYOzLSZcjkR16P0gHRQXjgfGDUGryYpwuRRq9k50iXMryN/69K8xKysLr732GlJSUlza1Wo1Xn/9dUyaNAkvv/xyr593+PBh5Ofn9+ra4uJixMfHQ6VSwWQyub3f3qZS9X3nviVLlmDjxo0oLi5moKCAExYGZA+ORXyEAmeutCBRrURaYiSiVaF5VHikUoZIJYNEb3HzK/KXPv2r3Lp1K6TSrnd5mz9/PnJycnr9vLS0NBQUFPTqWrVaDcAxZNHZsEZ7W2fDIT1JTEyEXC5HY2Njn+8l8odwuRQZyVHISPb9xGciov7oU6DoLky0S0tL6/XzNBoN5s6d25cSkJWVhZKSEtjtdpcx5NLSUkRERPRqH4ob1dTUwGw2cy8KIiKifurzKg+h5ebmoq6uzuUE1IaGBuzZswfTpk2DXH69G7iqqspl1YfRaOx0qej69esBAHfccYcPKyciEg4naJKviW4g8p577sGYMWPwH//xH86dMj/44APYbDYsX77c5drFixcDAPbu3QvAsUJkzpw5yMvLQ1paGmw2G/bt24fi4mLMnDkT48aN8/enQ0Tkc+3zKCo5QZN8SHSBQiqVYsOGDXj11VdRWFgIo9GIW2+9Fb/5zW+Qmpra7b3R0dGYMmUK9u/fj927d8Nms2HYsGFYtWpVryeHEhGJUfuqj/ZgwVBB3hZm7+74UOrSxYsXMW3aNKx8aAXio+OELoeIqNc6rvpgsKDeunSlAbkrf4NvvvkGgwcPdntfdHMoiAJVi9GCc/UtOFXbDF2zEYzqFKjad9QEOLeCvEd0Qx5EgUhvtOCLshpcvNoGAJBIgNljBmFIfITAlRF1jXMryJvYQ0HkBbVNBmeYAACbDfjbaR2MZh5cRYGNvRXkLQwURF5g6OTEy2utZpisHPcgcWCoIE9xyIPIC+Ij3c/VyEyOQqSi583giAIFz/8gT7CHgsgLNNEq5I4agHCFFAgDMpLVuH1YPCSS0DoRlIIDeyuoP9hDQeQFMkkYMgdEYVBcOCxWO6JUMkgZJkjEeKgY9RUDBZEXqXkKJhGFKA55EBERkcf46xQREXVKK8vgBE3qNfZQEBFRlzhBk3qLgYKIiLrVMVQwWFBXGCiIiKhH3FGTesJAQUREvcbeCuoKAwUFvDaTFRevtuLclRY0tpmFLoco5LG3gjrDVR4U0JoNFnxVXoMLDY6Dt8IVUsy+bRCSopQCV0ZE3PyKOmIPBQW06mttzjABOHor/nmuAVYbD90iIgokDBQU0BpaTG5tNY0GmKw2AaohIqKuMFBQQBsQo3JruzlJDZWMp3gSBQpO0CSAgYIC3MAYFcanxUPy/d/U1IQIZA+OQRjP3SIKCJygSe1ENynzzJkz+PDDD1FaWory8nIYjUZ88803GDx4cK+fcfToUaxZswbl5eVQq9WYMWMGnnnmGYSHh/uwcuoPlVyKCTfFIys5Cla7HdEqORQy5mCiQNM+QbOyuIzbdIco0X1nPnbsGAoLC6HX65Gent7n+ysqKrB48WIYjUasWrUK8+bNw0cffYQVK1b4oFryBklYGOIiFUhUKxkmiAJYe28Fh0BCk+h6KKZOnYrDhw9DrVZj06ZNKC8v79P9//M//4PY2FgUFhYiMjISADB48GD86le/QnFxMSZOnOiLsomIQgZ7K0KT6H7di42NhVqt7te9er0e//jHPzB79mxnmACAWbNmISIiAp9//rm3yiQiCmnsrQg9ogsUnqisrITFYsGoUa6JWaFQYMSIEaioqBCoMiKi4MQJm6FDdEMentDpdAAAjUbj9p5Go8GxY8f8XRIRUb9Z7XZIRbDkqT1U4PtQwWGQ4CRooLDZbDCbe3c2g1Lp+VbLBoMBgKNHorPnt79PRBTIrrWacaq2GWevtCA1IQJZA6IQG+H+fS3QcG5FcBM0UBw+fBj5+fm9ura4uBjx8fEefTyVyrFJksnkvvui0Wh0vk9EFKgMZiu+Kq9B9TXHL0A1jQacu9KCWbcNQri88w3fWowWnKtvRcXlJiRFKXFLSjQS1cKch8PzP4KXoIEiLS0NBQUFvbq2vxMxO2of6mgf+uhIp9MhKSnJ449BRORLV1vNzjDRrrbJiKstJoTHuu+lY7cDxy5cwz/PXQUAXLrahpM1zVgwbghiw+V+qZlCg6CBQqPRYO7cuX77eMOHD4dMJkNZWRnuvvtuZ7vJZEJFRQXuvfdev9VCRNQfki6mTIR1MZeiyWBGSdU1l7Y2kxVXmo0MFORVQb3KQ6vVorq62vk6KioKEydORFFREVpaWpztRUVFaG1tRW5urhBlEhH1WmyEAmmaSJe21IQIxEf0LRwIPZeTy0mDj+hWeTQ3N6OwsBAAnKsytm3bhqioKKSkpGD27NnOa2fOnInx48c7rweAFStW4Mc//jEWLVqE+fPno6amBu+99x7+7d/+DZMmTfLvJ0NE1EdKmQRTMjW4KTESVQ2tGBIXgdTECCi7mD8RrZLj9mFxOHimwdkWqZQKNocCuL7qgxM0g4voAkVjYyPWrVvn0vbuu+8CAMaPH+8SKDozcuRIvPfee1i7di0KCgqgVquxYMECPP300z6rmYjIm6JUcowaFINRg2J6vDYsDMgeHIu4CAVO1zZDE6XEzclRiAmA4Y6Oqz4ALicVO9EFisGDB6OysrJX13Z13e23344PP/zQm2UREQWsCIUUmQOikDkgSuhS3LC3IngE9RwKIiISh447anJuhTgxUBARUUBoP/8D4FbdYsRAQUREAcW5VTeJCgMFEREReYyBgoiIiDzGQEFERAGJ8yjERXTLRomIKPjxyHPxYQ8FEREFLK76EA/2UBARUUBjb4U4sIeCiIhEgb0VgY2BgoiIRIM7agYuBgoiIhKVjjtqUuBgoCAiIiKPMVAQERGRxxgoiIhItDiPInAwUBARkShxgmZgYaAgEpjNbse1VjOutppgtdmFLodIVHjkeeBgoCASUKvJimJtPbYeOI/C4vP422kd9EaL0GURiQ5DhfC4UyaRgC40tOKf5646X5deaERCpALZg2MFrIpInLijprDYQ0EkoDM6vVvbycvNsNk59EHUX+ytEIboeijOnDmDDz/8EKWlpSgvL4fRaMQ333yDwYMH9+r+RYsW4dChQ27tM2fOxOuvv+7tcom6pYlS4VSta6hIjlFBEhYmUEVEwYG9Ff4nukBx7NgxFBYWIj09Henp6SgvL+/zM1JSUvCLX/zCpW3QoEHeKpGo19I1kSirbkRjqxkAEKGUYmRKtMBVEQUPrSwD6ZbTqCwuY6jwMdEFiqlTp+Lw4cNQq9XYtGlTvwJFdHQ0Zs2a5YPqiPomLlKB+8cOxhW9EXa7HQlqJWLC5UKXRRRU2FvhH6KbQxEbGwu1Wu3xcywWC1paWrxQEZFnolQy3JQYiTSNmmGCyIc4t8K3RBcovEGr1WLMmDEYO3Ys7rjjDrz99tuw2WxCl0VEHmhsM+O7S43Yd7IO/6rTo81sFbokCkA8VMx3RDfk4akhQ4ZgwoQJyMzMhF6vx6efforXX38d1dXVeOGFF4Quj4j6ocVowWell6FrNgIASi82YnxaPCbcFM8JrkR+ImigsNlsMJvNvbpWqVR65WO+/PLLLq/nzJmDn//859i+fTsWL16MtLQ0r3wcIvKfK3qTM0y0O3LuKrIGRCEuQiFQVUShRdBAcfjwYeTn5/fq2uLiYsTHx/ukjiVLlmDPnj04ePAgAwWRCHW2b4fVbge386CuVHKCptcJGijS0tJQUFDQq2u9MRGzKwMGDAAANDY2+uxjEJHvxEcqEK6Qos10fd5EZnIUosNDblSXeqF9HgWXk3qXoP/aNBoN5s6dK2QJAIALFy4AgM96QIjIt2LC5Zhz2yAcv3gNNY0GZA6IQmZyFGSSkJx3Tr3UcY8KgL0Vngrq+K7VahEeHo6UlBQAgF6vh0KhgEJxfUzVarXi97//PSQSCSZOnChUqUTkIU2UElOzkmC12SGXMkhQ77C3wntEFyiam5tRWFgIwLFrJgBs27YNUVFRSElJwezZs53Xzpw5E+PHj3def+LECTzzzDPIy8vD0KFD0drais8//xxlZWV47LHHMGTIEP9/QkTkNZKwMEikXNVBfcfeCs+JLlA0NjZi3bp1Lm3vvvsuAGD8+PEugeJGKSkpGDt2LL788ktcuXIFEokEGRkZeOWVVzBnzhyf1k1kttpwrdUMux2IjZBDIeNv0USBhL0VnhFdoBg8eDAqKyt7de2N1w0ZMgS/+93vfFEWUbeaDRb8/V86nKpxHAQ2LCECU7KSuDMmUQBq762gvuGvSER+cL6+xRkmAOBcfStO17ofXU5EJFYMFER+UNXQ6tZ2RqfvdP8EIiIxYqAg8oNBseFubUMSIrgtNFEA4yFifSO6ORREYjQsMRIptc2ovmYAACRGKZCVHCVwVUTUFR553ncMFER+EBMuR97oFDS0mAA7EBepQIRCKnRZRNSDjstJGSq6x0BB5CfhcmmnQx9EFNjYW9E7nENBRETUC+3BgnMrOsdAQURE1EsdQwWDhSsGCiIioj7QyjLYW9EJBgoiIqJ+YG+FKwYKIiKifmJvxXUMFERERB5yrgQJYQwURERE5DEGCiIiIvIYAwUREZGXhPIETQYKIiIiLwj1CZoMFERERF4UqqGCZ3kQERF5WSie/8EeCiIiIh8Jpd4K9lAQERH5UKj0VoguUBQXF+OTTz7B0aNHUVNTA41Gg4kTJ+Kpp56CRqPp1TO0Wi1efvllHD16FHK5HHfddRdWrlyJ+Ph4H1dPREShSivLQLrltNBl+IzoAsWaNWvQ2NiI3NxcDBs2DBcuXMDWrVuxb98+FBUVISEhodv7a2pq8PDDDyM6OhorVqxAa2sr3n33XZw6dQrbt2+HXC7302dCREQUPEQXKFavXo2cnBxIJNenf9x5551YuHAh3n//fSxfvrzb+99++20YjUYUFhYiOTkZAJCdnY1HHnkERUVFmDdvnk/rJyIiCkaim5Q5btw4lzDR3hYbGwutVtvj/V9++SWmTp3qDBMAMGnSJAwbNgyff/651+slIiLqKFgnaIouUHSmpaUFLS0tiIuL6/a62tpa1NfXY9Qo9wkx2dnZqKio8FWJREREQX3keVAEis2bN8NsNmPGjBndXldXVwcAnU7e1Gg0qK+vh9Vq9UmNREREQPDuqCnoHAqbzQaz2dyra5VKZafthw8fxltvvYW8vDyMHz++22cYjUYAgEKh6PL5BoMBkZGRvaqJiIiov9pXfVQGyXJSQQPF4cOHkZ+f36tri4uL3ZZ1arVaLFu2DJmZmXjxxRd7fEZ7aDCZTG7vtYcNlUrVq3qIiIg81d5T0R4sxBwqBA0UaWlpKCgo6NW1arXa5fXly5fx6KOPIioqChs2bEBERESPz0hKSgIA6HQ6t/d0Oh0SEhIglUp7VQ8REZG3BENvhaCBQqPRYO7cuX2+7+rVq1iyZAlMJhM2b96MxMTEXt2XnJyM+Ph4lJW5j1mVlpZixIgRfa6FiIjIGzr2VoiR6CZltra24vHHH0dtbS02bNiA1NTULq+tqqpCVVWVS9vdd9+NvXv3ora21tlWXFyMc+fOITc312d1ExERBTPRbWz17LPPorS0FPfffz+0Wq3L3hOJiYmYPHmy8/XixYsBAHv37nW2LV26FHv27EF+fj4WLlyI1tZWbNy4EVlZWZg1a5bfPg8iIqJgIrpAcfLkSQDAzp07sXPnTpf3xo8f7xIoOjNw4EBs3boVr7zyCl577TXI5XJMmTIFq1ev7nT1BxERkb+JcYKm6AJFx96G/l6bkZGBjRs3eqskIiIir+k4QVNMoUJ0gYKIiCjYifHIc9FNyiQiIgoVYtpRkz0UREREAUwsvRXsoSAiIhKBQO+tYA8FERGRSARybwV7KIiIiEQmEHsrGCiIiIhEqGOoCIRgwUBBREQkUlpZRsD0VjBQEBERiZxzboWAGCiIiIjIYwwURERE5DEGCiIioiAh5ARNBgoiIqIgIPQETQYKIiKiICJUqOBOmUREREFGiB012UNBREQUpPzZW8EeCiIioiDmr94K9lAQERGFAF9vfsVAQURERB5joCAiIiKPiW4ORXFxMT755BMcPXoUNTU10Gg0mDhxIp566iloNJoe71+1ahV2797t1j569Ghs377dFyUTEREFjMriMp/MoxBdoFizZg0aGxuRm5uLYcOG4cKFC9i6dSv27duHoqIiJCQk9PiM8PBwPP/88y5t8fHxviqZiIgoIGhlGUi3nHau+vBmsBBdoFi9ejVycnIgkVwfrbnzzjuxcOFCvP/++1i+fHmPz5DJZJg1a5YvyyQiIgpI7ZMz24OFt0KF6OZQjBs3ziVMtLfFxsZCq9X2+jlWqxV6vd7b5REREYlCxz0qvLFPhegCRWdaWlrQ0tKCuLi4Xl+fk5ODnJwcTJgwAQUFBTAajT6ukoiIKLB48/wP0Q15dGbz5s0wm82YMWNGj9dqNBr89Kc/xYgRI2Cz2bBv3z5s2rQJWq0Wf/jDH/xQLRERUWDxxtwKQQOFzWaD2Wzu1bVKpbLT9sOHD+Ott95CXl4exo8f3+NznnnmGZfXeXl5SE5OxsaNG7F//35Mnjy5V/UQEREFE0/nVggaKA4fPoz8/PxeXVtcXOy2EkOr1WLZsmXIzMzEiy++2O86lixZgo0bN6K4uJiBgoiIQlp/eysEDRRpaWkoKCjo1bVqtdrl9eXLl/Hoo48iKioKGzZsQERERL/rSExMhFwuR2NjY7+fQUREFCz601shaKDQaDSYO3dun++7evUqlixZApPJhM2bNyMxMdGjOmpqamA2m7kXBfWo2WDBFb0RZqsNCZFKJKgVQpdEROQz7b0VvSG6SZmtra14/PHHUVtbiy1btiA1NbXLa6uqqgAAQ4cOBQAYjUaYzWa33o7169cDAO644w4fVU3BoKnNjE9LL0PX7FgRJJWEYe7YQUiJDRe4MiIi4YkuUDz77LMoLS3F/fffD61W67L3RGJiossciMWLFwMA9u7dCwDQ6XSYM2cO8vLykJaW5lzlUVxcjJkzZ2LcuHG9rsNqtQIAGvUcJgkVWl0LLjfUO19bAPy14hymjUiCTBIUK7CJiNxEWfVQX2lATYPj5137z78biS5QnDx5EgCwc+dO7Ny50+W98ePHdzupMjo6GlOmTMH+/fuxe/du2Gw2DBs2DKtWrer15NB2Op0OAPD2J+/28TOgYFJ3Hjh2XOgqiIh87KPrf9TpdJ2ODoTZ7Xa7H0sKGgaDAWVlZdBoNJBKpUKXQ0RE5FNWqxU6nQ6jRo2CSqVye5+BgoiIiDzGgV8iIiLyGAMFEREReYyBgoiIiDzGQEFEREQeY6AgIiIijzFQEBERkccYKIiIiMhjDBRERETkMdFtvU3e8+2332Lz5s2orKzEtWvXEBcXhzFjxmD58uXIyMgQujy/Ky4uxieffIKjR4+ipqYGGo0GEydOxFNPPQWNRiN0eX535swZfPjhhygtLUV5eTmMRiO++eYbDB48WOjSfMpkMmHdunUoKipCU1MTsrKysGLFCkycOFHo0gRRV1eHLVu24Pjx4ygrK0Nrayu2bNmCCRMmCF2a35WWlmL37t04ePAgqqurERsbi9tuuw2/+MUvuj2oMlSwhyKEabVaREREYNGiRfiv//ovPPTQQ6ioqMD8+fNx6tQpocvzuzVr1uDQoUOYPn06fvWrX2HmzJn47LPPMGfOHNTX1/f8gCBz7NgxFBYWQq/XIz09Xehy/GbVqlXYvHkz7rvvPvzyl7+ERCLBY489hpKSEqFLE8TZs2fxzjvvoLa2FpmZmUKXI6g//OEP+OqrrzBp0iT88pe/xIIFC3Do0CHMnj3b5aDKkGUn6uDKlSv2W265xf78888LXYrfHTp0yG61Wt3ahg8fbv/d734nUFXCuXr1qr25udlut9vt7733nn348OH2CxcuCFyVbx0/ftw+fPhw+3vvvedsMxgM9unTp9sfeugh4QoTUHNzs72hocFut9vtX331lX348OH2AwcOCFyVMI4cOWI3Go0ubWfPnrWPGjXKvnLlSoGqChzsoSAX8fHxUKlUaGpqEroUvxs3bhwkNxxDPm7cOMTGxobkbx+xsbFQq9VCl+FXe/bsgVwux/z5851tSqUS8+bNw5EjR1BXVydgdcJQq9WIi4sTuoyAMHbsWCgUCpe2YcOGISMjIyS/R9yIcygIzc3NMJvN0Ol02Lx5M/R6fciOF9+opaUFLS0t/IYaIioqKnDTTTchMjLSpT07Oxt2ux0VFRVISkoSqDoKRHa7HVeuXEFWVpbQpQiOgYLwk5/8BCdOnAAARERE4IknnsDcuXMFriowbN68GWazGTNmzBC6FPIDnU6H5ORkt/b2Sbmh2ENB3fvkk09QW1uLFStWCF2K4BgogoTNZoPZbO7VtUql0uX1f//3f6OpqQkXLlzA7t27YTAYYLFYIJfLfVGqX3jy9Wh3+PBhvPXWW8jLy8P48eO9WZ7feePrEQoMBkOnf+/bvyZGo9HfJVEA02q1eOGFF5CTk4NZs2YJXY7gGCiCxOHDh5Gfn9+ra4uLixEfH+98nZ2d7fzzj370I8ycORMAsHLlSu8W6UeefD0AxzeKZcuWITMzEy+++KIvSvQrT78eoUKlUnUavNqDRCiHLXKl0+nws5/9DDExMVi3bp3b/KtQxEARJNLS0lBQUNCra7ubaBcdHY1JkybhT3/6k6gDhSdfj8uXL+PRRx9FVFQUNmzYgIiICF+U6Ffe+vsR7DQaTafDGjqdDgA4f4IAOOadPfbYY2hubsYHH3wQkvvUdIaBIkhoNBqvzXswGAxobm72yrOE0t+vx9WrV7FkyRKYTCZs3rwZiYmJPqjO/7z59yOYZWVlobCwEC0tLS4TM48fP+58n0Kb0WjE0qVLce7cOWzatAlpaWlClxQw2EcTwhoaGtzaqqur8Y9//AMjR44UoCJhtba24vHHH0dtbS02bNjAne9CUG5uLsxmM3bs2OFsM5lM2LVrF8aOHdvphE0KHVarFb/4xS9w7NgxrFu3DmPGjBG6pIDCHooQ9uMf/xhZWVkYNWoUYmNjcf78efzxj3+E0WjE008/LXR5fvfss8+itLQU999/P7Rarcu68sTEREyePFnA6vyvubkZhYWFABy7ZgLAtm3bEBUVhZSUFMyePVvI8nxi9OjRyM3Nxdq1a6HT6TB06FDs3r0b1dXVvR4yCkbr168HAOe/iaKiIhw5cgTR0dFYuHChkKX51SuvvIK9e/firrvuwrVr11BUVOR8LzIyEtOnTxewOuGF2e12u9BFkDDeeecdfPXVVzh//jz0ej3i4uJw++23Y+nSpSHZtTt16lRcunSp0/fGjx/v/OEaKi5evIhp06Z1+l4wfz2MRiN++9vf4k9/+hMaGxuRmZmJp59+GpMmTRK6NMF0teX2oEGDsHfvXj9XI5xFfTNqdwAAAqlJREFUixbh0KFDnb4Xal+LzjBQEBERkcc4h4KIiIg8xkBBREREHmOgICIiIo8xUBAREZHHGCiIiIjIYwwURERE5DEGCiIiIvIYAwURERF5jFtvE5EonTlzBjt27MCJEydQXl6O5uZmLFu2DMuXLxe6NKKQxB4KIhKlY8eO4b333kNNTU1IHmZHFGjYQ0FEojR16lQcOnQI0dHR+O677zBv3jyhSyIKaeyhIKKAYbFY8OMf/xhjxoxxOe0VAD766CNkZmZi3bp1AIDY2FhER0cLUSYRdYKBgogChkwmw2uvvQa5XI6nn34aJpMJAHD69Gm8/PLLyMnJwbJlywSukog6w0BBRAFl0KBB+PWvf42TJ0/ilVdegcFgwIoVK6BUKrF27VpIpVKhSySiTnAOBREFnLvvvhsPPvggtm3bhvLycpw+fRpvvPEGUlJShC6NiLrAHgoiCkirV6/G0KFDUVJSggULFuDuu+8WuiQi6gYDBREFpJMnT+Ly5csAHHMoLBaLwBURUXcYKIgo4Oj1ejz99NOIjY3FihUrUFJSgjfeeEPosoioG5xDQUQB57nnnkN1dTXeffddTJw4EeXl5diwYQMmTpyIH/zgB0KXR0SdCLPb7XahiyAiardjxw786le/wtKlS7FixQoAQFNTE2bPng2z2YxPPvkEcXFxaG5uRmFhIQCgrq4OH3zwASZMmOAMHFOnTkVWVpZgnwdRqGGgIKKAodVqcf/99yMrKwtbt26FTHa9E7WkpAQLFy7EnXfeibfffhsXL17EtGnTunxWQUEB5s6d64+yiQgMFEREROQFnJRJREREHmOgICIiIo8xUBAREZHHGCiIiIjIYwwURERE5DEGCiIiIvIYAwURERF5jIGCiIiIPMZAQURERB5joCAiIiKP/X9KQTycmIoTuAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plot Learning Curve**"
      ],
      "metadata": {
        "id": "_UFUvD8ZzRx6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_learning_curve(err_all):\n",
        "  err = [err[1][1] for err in err_all]\n",
        "  plt.plot(np.arange(len(err_all)),err,'r-')\n",
        "  plt.xlabel('Iter #')\n",
        "  plt.ylabel('J(w)')"
      ],
      "metadata": {
        "id": "limzl67PzVLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lsc.sgd(x1_train, y1_train_trans,num_epochs=100,reg_rate=0)\n",
        "plot_learning_curve(lsc.err_all)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "cs5gfqZ90ooV",
        "outputId": "4ee6ad86-ce79-4e9b-fe23-b838dab0dd27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predict:  0 y_hat:  (1,)\n",
            "predict:  0 y_hat:  (37,)\n",
            "Calculate_gradient: () (37, 2)\n",
            "predict:  0 y_hat:  (37,)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-100-ed3e8b3f9927>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msgd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1_train_trans\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreg_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplot_learning_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merr_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-96-25e776962826>\u001b[0m in \u001b[0;36msgd\u001b[0;34m(self, X, y, num_epochs, reg_rate)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merr_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreg_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_schedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-96-25e776962826>\u001b[0m in \u001b[0;36mcalculate_gradient\u001b[0;34m(self, X, y, reg_rate)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Calculate_gradient:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mreg_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m     \u001b[0;31m#grad = np.transpose(X) @ (self.predict_internal(X) - y) + reg_rate * self.w\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (3,2) (3,) "
          ]
        }
      ]
    }
  ]
}