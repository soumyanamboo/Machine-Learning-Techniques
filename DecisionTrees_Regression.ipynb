{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP5liRiTxe6HCFsn8NCeGm3"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9GWl2TXKiKv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "present_price = np.array([5.59, 9.54, 9.85, 4.15, 6.87, 9.83, 8.12, 8.61, 8.89, 8.92]).reshape(10, -1)\n",
        "km_driven = np.array([27000, 43000, 6900, 5200, 42450, 2071, 18796, 33429, 20273, 42376]).reshape(10, -1)\n",
        "age = np.array([8, 9, 5, 11, 8, 4, 7, 7, 6, 7]).reshape(10, -1) \n",
        "selling_price = np.array([3.35, 4.75, 7.25, 2.85, 4.6, 9.25, 6.75, 6.5, 8.75, 7.45]).reshape(10, -1)"
      ],
      "metadata": {
        "id": "o4R_2xUAK0UF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset = {'present_price': present_price, 'km_driven':km_driven, 'age':age, 'selling_price':selling_price }\n",
        "# df1 = pd.DataFrame(X)\n",
        "# df1\n",
        "X  = np.concatenate([present_price, km_driven, age, selling_price], axis=1)\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "la2FmC82K1bG",
        "outputId": "02776b32-c22a-4c4e-dc07-b01ecc1ae17e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.5900e+00, 2.7000e+04, 8.0000e+00, 3.3500e+00],\n",
              "       [9.5400e+00, 4.3000e+04, 9.0000e+00, 4.7500e+00],\n",
              "       [9.8500e+00, 6.9000e+03, 5.0000e+00, 7.2500e+00],\n",
              "       [4.1500e+00, 5.2000e+03, 1.1000e+01, 2.8500e+00],\n",
              "       [6.8700e+00, 4.2450e+04, 8.0000e+00, 4.6000e+00],\n",
              "       [9.8300e+00, 2.0710e+03, 4.0000e+00, 9.2500e+00],\n",
              "       [8.1200e+00, 1.8796e+04, 7.0000e+00, 6.7500e+00],\n",
              "       [8.6100e+00, 3.3429e+04, 7.0000e+00, 6.5000e+00],\n",
              "       [8.8900e+00, 2.0273e+04, 6.0000e+00, 8.7500e+00],\n",
              "       [8.9200e+00, 4.2376e+04, 7.0000e+00, 7.4500e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split(dataset, feature_index, threshold):\n",
        "  # left_node = []\n",
        "  # right_node = []\n",
        "  # for i in range(len(dataset)):\n",
        "  #   if(dataset[i][feature_index] <= threshold):\n",
        "  #     left_node.append(X[i])\n",
        "  #   else:\n",
        "  #     right_node.append(X[i])\n",
        "  # return np.array(left_node), np.array(right_node)\n",
        "  left_node = np.array([row for row in dataset if row[feature_index] <= threshold])\n",
        "  right_node = np.array([row for row in dataset if row[feature_index] > threshold])\n",
        "  \n",
        "  return left_node, right_node"
      ],
      "metadata": {
        "id": "MQWAEbBbM4fa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l, r = split(X, 0 ,7)"
      ],
      "metadata": {
        "id": "fXX-FlsEOPra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def varience_reduction(parent, l_child, r_child):\n",
        "  l_weight = len(l_child) / len(parent)\n",
        "  r_weight = len(r_child) / len(parent)\n",
        "  # total_var = np.var(parent)\n",
        "  # left_var = np.var(l_child)\n",
        "  # right_var = np.var(r_child)\n",
        "  # reduction = total_var - (l_weight * left_var + r_weight * r_child)\n",
        "  reduction = np.var(parent) - (l_weight * np.var(l_child) + r_weight * np.var(r_child))\n",
        "  return reduction"
      ],
      "metadata": {
        "id": "VMm_FOiWOVEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(varience_reduction(X[:, -1], l[:,-1], r[:,-1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-v6Qpk0EQAbc",
        "outputId": "d714d7b3-ab80-4d90-9a38-bbf753f2261c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.786785714285714\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#predict - np.mean"
      ],
      "metadata": {
        "id": "TctRWvB8QmrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_best_split(dataset, num_samples, num_features):\n",
        "  # returns a dictionary of feature_index, threshold, dataset_left, dataset_right, max_varience_reduction\n",
        "  best_split = {}\n",
        "  max_reduction = -float('inf')\n",
        "  for index in range(num_features):\n",
        "    possible_values = np.unique(dataset[:, index])\n",
        "    for threshold in possible_values:\n",
        "      left_node, right_node = split(dataset, index, threshold)\n",
        "      if(len(left_node) > 0 and len(right_node) > 0):\n",
        "        var_red = varience_reduction(dataset[:, -1],left_node[:, -1], right_node[:, -1])\n",
        "        if(var_red > max_reduction):\n",
        "          max_reduction = var_red\n",
        "          best_split['feature_index'] = index\n",
        "          best_split['threshold'] = threshold\n",
        "          best_split['dataset_left'] = left_node\n",
        "          best_split['dataset_right'] = right_node\n",
        "          best_split['max_var_reduction'] = var_red\n",
        "\n",
        "  return best_split"
      ],
      "metadata": {
        "id": "m_6VEaWJQrFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_best_split(X, X.shape[0], X.shape[1]-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yUzcTIkWFPC",
        "outputId": "c10269cb-d8fd-47e6-9bec-9bd0f836cbd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dataset_left': array([[5.5900e+00, 2.7000e+04, 8.0000e+00, 3.3500e+00],\n",
              "        [9.5400e+00, 4.3000e+04, 9.0000e+00, 4.7500e+00],\n",
              "        [9.8500e+00, 6.9000e+03, 5.0000e+00, 7.2500e+00],\n",
              "        [6.8700e+00, 4.2450e+04, 8.0000e+00, 4.6000e+00],\n",
              "        [9.8300e+00, 2.0710e+03, 4.0000e+00, 9.2500e+00],\n",
              "        [8.1200e+00, 1.8796e+04, 7.0000e+00, 6.7500e+00],\n",
              "        [8.6100e+00, 3.3429e+04, 7.0000e+00, 6.5000e+00],\n",
              "        [8.8900e+00, 2.0273e+04, 6.0000e+00, 8.7500e+00],\n",
              "        [8.9200e+00, 4.2376e+04, 7.0000e+00, 7.4500e+00]]),\n",
              " 'dataset_right': array([[4.15e+00, 5.20e+03, 1.10e+01, 2.85e+00]]),\n",
              " 'feature_index': 2,\n",
              " 'max_var_reduction': 1.209999999999999,\n",
              " 'threshold': 9.0}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    }
  ]
}