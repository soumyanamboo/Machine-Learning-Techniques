{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPzMs3tK2vOnHse7d9NXWgk"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Random Foreset  \n",
        "##Algorithm   \n",
        "###Input:   \n",
        "Training data D with shape (n, m) where n is the number of samples and m is the number of features.   \n",
        "###Steps:\n",
        "1. Sample q dataset each of shape (n, m) say $D_1, D_2, ... D_q$ with replacement from D.   \n",
        "2. In each of the dataset $D_i$ select u out of m features where u<=m, before each split and train a full decision tree $h_j(x)$.   \n",
        "3. The final predictor is:   \n",
        "  * For regression, an average output from q regressors is assigned to the new example.   \n",
        "  $$ h(x) = \\frac{1}{q} Î£_{j=1}^q h_j(x)   \n",
        "  $$   \n",
        "  * For classification, a majority voting is taken and class label with maximum number of votes is assigned to the new example."
      ],
      "metadata": {
        "id": "2VIpQHMrswgJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ov-JN6IRsuIG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Random Forest Bagging   \n",
        "Define a function bag to create bootstrap samples $D_1, D-2, ... D_q $ from the original dataset $D$.   \n",
        "The key step is np.random.choice with size = n_samples and replace=True, which ensures that the bootstrap samples has the same number of samples as the original dataset and it is obtained by sampling with replacement."
      ],
      "metadata": {
        "id": "chzdzCiIviFw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bag(X, y):\n",
        "  n_samples = X.shape[0]\n",
        "\n",
        "  indices = np.random.choice(n_samples, size=n_samples, replace=True, random_state=1)\n",
        " # indices = np.random.choice(n_samples, size=n_samples, replace=True)\n",
        "\n",
        "  return X[indices], y[indices]"
      ],
      "metadata": {
        "id": "wnah6WL2vc4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Majority Voting"
      ],
      "metadata": {
        "id": "BCKvLmiew5-9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def most_common_label(y):\n",
        "  counter = Counter(y)\n",
        "  most_common = counter.most_common(1)[0][0]\n",
        "  return most_common"
      ],
      "metadata": {
        "id": "zXMEXM47wYWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Random Forest Class"
      ],
      "metadata": {
        "id": "TxSJvYnVxZ_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RandomForest:\n",
        "  def __init__(self, n_trees=10, min_sapmle_split=2, max_depth=100, max_features=None):\n",
        "    self.n_trees = n_trees\n",
        "    self.min_sapmle_split = min_sapmle_split\n",
        "    self.max_depth = max_depth\n",
        "    self.max_features = max_features\n",
        "    self.trees = []\n",
        "  \n",
        "  def fit(self, X, y):\n",
        "    self.trees = []\n",
        "    for _ in range(self.n_trees):\n",
        "      tree = DecisionTreeClassifier(min_samples_split=self.min_sapmle_split,\n",
        "                                    max_depth = self.max_depth,\n",
        "                                    max_features=self.max_features\n",
        "                                    )\n",
        "      X_samples, y_samples = bag(X, y)\n",
        "      tree.fit(X_samples, y_samples)\n",
        "      self.trees.append(tree)\n",
        "  \n",
        "  def predict(self, X):\n",
        "    tree_predict = np.array([tree.predict(X) for tree in self.trees])\n",
        "    tree_predict = np.swapaxes(tree_predict, 0, 1)   #each of the trees will give out prediction\n",
        "    y_predict = [most_common_label(tree_pred) for tree_pred in tree_predict]\n",
        "    return np.array(y_predict)"
      ],
      "metadata": {
        "id": "cEDYgY-JxdNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest Implementation:"
      ],
      "metadata": {
        "id": "Wf0qCrHVz6Yt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  accuracy = np.sum(y_pred == y_true) / len(y_true)\n",
        "  return accuracy\n",
        "\n",
        "data = datasets.load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "clf = RandomForest(n_trees=10, max_depth=100, max_features='sqrt')\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "acc = accuracy(y_test, y_pred)\n",
        "print('Accuracy: ', acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bh1LbaC5yGdF",
        "outputId": "29eb2ee8-d234-4e29-e552-1de12e8b0695"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.9473684210526315\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "matrix = confusion_matrix(y_test, y_pred)\n",
        "print(matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Htux0fz330EU",
        "outputId": "e0114e86-4cd1-437c-e9d6-2efd8bab54d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[36  6]\n",
            " [ 0 72]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDJ6woYe4IQ_",
        "outputId": "89deda82-a3d1-4ce9-fe80-011ee6579d8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.86      0.92        42\n",
            "           1       0.92      1.00      0.96        72\n",
            "\n",
            "    accuracy                           0.95       114\n",
            "   macro avg       0.96      0.93      0.94       114\n",
            "weighted avg       0.95      0.95      0.95       114\n",
            "\n"
          ]
        }
      ]
    }
  ]
}